{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMXUiJwnJkPLHfBJkl2JSvD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youse0ng/AIProgramming/blob/main/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D5%EC%A3%BC%EC%B0%A8_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuBGkA8AUXxR"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import cifar10 # cifar10 데이터셋\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras import utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  os.mkdir('my_log_dirs8')  # my_log_dirs8 이라는 폴더생성\n",
        "  callback=[keras.callbacks.TensorBoard(log_dir='my_log_dirs8',histogram_freq=1,embeddings_freq=1)]\n",
        "except:\n",
        "  print(\"폴더가 이미 있습니다.\")"
      ],
      "metadata": {
        "id": "yPp_7no6UZLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "UcNa2LTZUdU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train,y_train.shape"
      ],
      "metadata": {
        "id": "DN4k5h0tfXpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "metadata": {
        "id": "OQi771SLeW3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "P0NosTYAcgEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0].shape"
      ],
      "metadata": {
        "id": "f6FnFOr1eHou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "JD4I_OiXgBMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width = 32\n",
        "height = 32\n",
        "channel = 3\n",
        "# 순차적 모델을 만들기 위한 Sequential() 함수\n",
        "model = Sequential(name='CIFAR10_CNN') # 6개의 Conv2d layer\n",
        "# filters : Kernel 그룹의 갯수 / kernel_size : Kernel 크기\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu',\n",
        "                 input_shape=(width, height, channel)))\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "# pool_size : MaxPooling 의 Window size\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "# N차원 배열을 1차원으로 펴줍니다\n",
        "model.add(layers.Flatten())\n",
        "# 출력층 MLP\n",
        "model.add(layers.Dense(10, activation='softmax')) # 10개의 node의 값을 -> softmax 함수로 통해 확률로 바꿈. 0~9까지의 클래스 확률로 나뉘어지고 제일 높은 값의 인덱스가 클래스넘버가 된다.\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Oh4_xdKuUug-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255.0   # x_train의 화소값 (np.array)로 될 것이니까... astype으로 데이터 자료형을 float32로 바꾸고 normalization\n",
        "x_test = x_test.astype('float32') / 255.0 # 0~1사이의 화소값\n",
        "\n",
        "y_train = utils.to_categorical(y_train) # (이게 아마... 범주형 카테고리를 기계가 이해할 수 있는 원핫 인코딩하는 거였나 기억이 잘안난다.)\n",
        "y_test = utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "hiDbAakWVr3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "XVy6JwtsfKBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[1]"
      ],
      "metadata": {
        "id": "0qy97-ifeSGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(keras.callbacks.Callback): # keras.callbacks 모듈에 있는 Callback이라는 클래스를 상속\n",
        "  def on_epoch_end(self, epoch, logs={}): # 상속하고 def __init__을 안해도 자연스럽게 Callback의 def __init__ 을 사용할 수 있다.\n",
        "    if logs.get('acc')>0.97:\n",
        "      print(\"Cancel the training\")\n",
        "      self.model.stop_training=True # def __init__ 에 있는 self.model.stop_training에 접근\n",
        "\n",
        "callbacks=myCallback() # callbacks 인스턴스 = 클래스 (선언) 그러면 callbacks.on_epoch_end(epoch) 로 메소드를 사용할 수 있다."
      ],
      "metadata": {
        "id": "gbzsCQCyWqeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks=[keras.callbacks.TensorBoard(\n",
        "    log_dir='my_log_dir7',\n",
        "    histogram_freq=1,\n",
        "    embeddings_freq=1,\n",
        ")\n",
        "]"
      ],
      "metadata": {
        "id": "DV_kuPUaWtNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #"
      ],
      "metadata": {
        "id": "Guk50UORVbZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train, y_train,\n",
        "                 epochs=5,\n",
        "                 batch_size=16,\n",
        "                 validation_data=(x_test, y_test),callbacks=callbacks)"
      ],
      "metadata": {
        "id": "-k1PcgVMVJJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch 15: train_정확도 90% # val_정확도:0.7342 이 가장 무난하다."
      ],
      "metadata": {
        "id": "45x-Yb9nhgd6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OWD8PFY2hybJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist.history['loss'], 'y', label='train loss')\n",
        "plt.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "plt.ylim([0.0, 2.5])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FkHLDYu4VNiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['accuracy'], 'y', label='train acc')\n",
        "plt.plot(hist.history['val_accuracy'], 'r', label='val acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VhEv1ANBh_Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이런 경우에는 train_acc는 높고, val_acc는 상대적으로 낮다.\n",
        "\n",
        "train 데이터셋을 학습을 너무 잘해서 나타나는 결과인 overfitting 과적합 현상이라고 생각된다.\n",
        "\n",
        "과적합을 방지할 방법 중 모델에 적용할 기법은\n",
        "\n",
        "* 배치 정규화\n",
        "* 드롭아웃\n",
        "* 얼리스탑핑\n",
        "\n",
        "데이터셋에 적용할 기법\n",
        "* Data Augmentation"
      ],
      "metadata": {
        "id": "ps4vxqpXiK9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "을 다음에 적용해보자"
      ],
      "metadata": {
        "id": "DqiHtacti0ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=my_log_dirs8"
      ],
      "metadata": {
        "id": "03BRqvzVW0L-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}